{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kan-bayashi/INTERSPEECH19_TUTORIAL/blob/master/notebooks/sprocket/sprocket.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"sprocket_png/image0001.png\" width=85%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0002.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0003.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0004.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0005.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0006.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0007.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0008.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0009.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0010.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0011.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0012.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0013.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0014.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0015.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0016.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0017.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0018.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 0: Setup\n",
    "## Print Python3 version and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38718,
     "status": "ok",
     "timestamp": 1566259579374,
     "user": {
      "displayName": "Kazuhiro Kobayashi",
      "photoUrl": "",
      "userId": "07649292297537623984"
     },
     "user_tz": -540
    },
    "id": "ILk9Kg9yTl-Q",
    "outputId": "dcf9cbd1-e0b7-4b1c-ba43-891ea2d43e16",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!python -V\n",
    "!which python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Install Python3 dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install -Uq pip\n",
    "!pip3 install -q sprocket-vc\n",
    "!echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E77tnLMiUK2o",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Clone sprocket repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8327,
     "status": "ok",
     "timestamp": 1566260056250,
     "user": {
      "displayName": "Kazuhiro Kobayashi",
      "photoUrl": "",
      "userId": "07649292297537623984"
     },
     "user_tz": -540
    },
    "id": "I4cTFE75UMJ6",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3f482a5c-49c1-4ff7-cb86-0647521efdcd"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/k2kobayashi/sprocket.git\n",
    "import os\n",
    "egs_dir = os.getcwd() + \"/sprocket/example\"\n",
    "os.chdir(egs_dir)\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzbTrLCQT2uY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Download VCC2018 dataset \n",
    "In this tutorial, we use a subset of VCC2018 dataset\n",
    "- VCC2SM1: Male source speaker\n",
    "- VCC2TF1: Female target speaker\n",
    "\n",
    "### Download fullset  \n",
    "If you want to use allset of VCC2018 dataset, please delete comment out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 633228,
     "status": "ok",
     "timestamp": 1566260750371,
     "user": {
      "displayName": "Kazuhiro Kobayashi",
      "photoUrl": "",
      "userId": "07649292297537623984"
     },
     "user_tz": -540
    },
    "id": "IHqlbCI1T5HV",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b3f302be-b593-4579-f760-c367f542f87a"
   },
   "outputs": [],
   "source": [
    "# Download subset of VCC2018 dataset for this tutorial \n",
    "!wget -q \"https://drive.google.com/a/g.sp.m.is.nagoya-u.ac.jp/uc?authuser=1&id=1Gl5RjovvueMiB7XoUZsrvnBOZLiC23EU&export=download\" -O wav.tar.gz\n",
    "!tar zxf wav.tar.gz -C data\n",
    "!tree -L 2 data/wav\n",
    "\n",
    "# Downlaod fullset of VCC2018 dataset (it takes long time...)\n",
    "# !python3 download_speech_corpus.py downloader_conf/vcc2018.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TusmFxjXU5NI",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step0:  Initialization\n",
    "Run ```ininitialize.py``` in ```sprocket/example``` directory\n",
    "\n",
    "### Options for ```initialize.py```\n",
    "- -1: Generate list file\n",
    "- -2: Generate yml files (speaker- and pair-dependent)\n",
    "- -3: Generate histograms\n",
    "- <source_speaker\\>: Source speaker label (e.g., VCC2SM1)\n",
    "- <target_speaker\\>: Target speaker label (e.g., VCC2TF1)\n",
    "- <sampling_frequency\\>: Sampling frequency of audio files (22050 for VCC2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run ```initialize.py``` to generate list and yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1566262367215,
     "user": {
      "displayName": "Kazuhiro Kobayashi",
      "photoUrl": "",
      "userId": "07649292297537623984"
     },
     "user_tz": -540
    },
    "id": "r1bvVHXOU8Ma",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c15d4c32-5c93-4f49-ce84-c4c79fbf742d"
   },
   "outputs": [],
   "source": [
    "# python3 initialize.py -1 -2 <source_speaker> <target_speaker> <sampling_frequency>\n",
    "!python3 initialize.py -1 -2 VCC2SM1 VCC2TF1 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- List file (```list/*.list```): Line up path of audio files without extention\n",
    "    - Training: ```*_train.list```\n",
    "    - Evaluation: ```*_eval.list``` \n",
    "- Speaker-dependent yml file (```conf/speaker/*.yml```)\n",
    "    - Define speaker-dependent parameters\n",
    "- Pair-dependent yml file (```conf/pair/*.yml```)\n",
    "    - Define pair-dependent parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modify list files to specify training and evaluation utterances\n",
    "\n",
    "We use following utterances:\n",
    "- Training: 20 utterances\n",
    "- Evaluation: 5 utterances\n",
    "\n",
    "Attention to create list\n",
    "- Length and order of training list files of source and target speaker must be same\n",
    "- Do not overlap utterances between training and evaluation for fair evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"list\")\n",
    "!echo \"$(head -n 20 VCC2SM1_train.list)\" > VCC2SM1_train.list\n",
    "!echo \"$(head -n 20 VCC2TF1_train.list)\" > VCC2TF1_train.list\n",
    "!echo \"$(tail -n 5 VCC2SM1_eval.list)\" > VCC2SM1_eval.list\n",
    "!echo \"$(tail -n 5 VCC2TF1_eval.list)\" > VCC2TF1_eval.list\n",
    "!echo \"Training set\"\n",
    "!paste VCC2SM1_train.list VCC2TF1_train.list\n",
    "!echo \"Evaluation set\"\n",
    "!paste VCC2SM1_eval.list VCC2TF1_eval.list\n",
    "os.chdir(egs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set speaker-dependent and pair-dependent parameters\n",
    "### Representative parameters\n",
    "- Speaker-dependent\n",
    "    - F0 range\n",
    "    - Power threshold\n",
    "- Pair-dependent\n",
    "    - \\# of mixture components\n",
    "    - \\# of iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate F0 histogram\n",
    "Run ```initializa.py``` with ```-3``` option\n",
    "- Extract F0 and npow\n",
    "    - F0: Fundamental frequency\n",
    "    - npow: Power sequence\n",
    "- Create their histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 initialize.py -3 VCC2SM1 VCC2TF1 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0019.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Show F0 historgram\n",
    "F0 histogram saves into ```conf/figure``` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!find conf/figure | grep f0histogram.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display_png\n",
    "print(\"VCC2SM1\")\n",
    "display_png(Image(\"conf/figure/VCC2SM1_f0histogram.png\"))\n",
    "print(\"VCC2TF1\")\n",
    "display_png(Image(\"conf/figure/VCC2TF1_f0histogram.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modify speaker-dependent yml\n",
    "Set F0 range in each source and target speaker\n",
    "\n",
    "- VCC2SM1:\n",
    "    - Minimum F0: 50\n",
    "    - Maximum F0: 190\n",
    "- VCC2TF1:\n",
    "    - Minimum F0: 140\n",
    "    - Maximum F0: 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('conf/speaker')\n",
    "import yaml\n",
    "with open('VCC2SM1.yml', 'r') as fp:\n",
    "    yml = yaml.load(fp, Loader=yaml.BaseLoader)\n",
    "    yml['f0']['minf0'] = 50\n",
    "    yml['f0']['maxf0'] = 190\n",
    "with open('VCC2SM1.yml', 'w') as fp:\n",
    "    yaml.dump(yml, fp)\n",
    "with open('VCC2TF1.yml', 'r') as fp:\n",
    "    yml = yaml.load(fp, Loader=yaml.BaseLoader)\n",
    "    yml['f0']['minf0'] = 140\n",
    "    yml['f0']['maxf0'] = 320\n",
    "with open('VCC2TF1.yml', 'w') as fp:\n",
    "    yaml.dump(yml, fp)\n",
    "\n",
    "# confirm\n",
    "!cat VCC2SM1.yml VCC2TF1.yml | grep f0\n",
    "os.chdir(egs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modify pair-dependent yml file\n",
    "\n",
    "Set following parameters in this tutorial\n",
    "\n",
    "- Covariance type to ```block_diag```\n",
    "- \\# of mixture components for mel-cepstrum GMM to 16\n",
    "- \\# of iteration to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('conf/pair')\n",
    "import yaml\n",
    "with open('VCC2SM1-VCC2TF1.yml', 'r') as fp:\n",
    "    yml = yaml.load(fp, Loader=yaml.BaseLoader)\n",
    "    yml['GMM']['mcep']['covtype'] = 'block_diag'\n",
    "    yml['GMM']['mcep']['n_mix'] = 16\n",
    "    yml['jnt']['n_iter'] = 2\n",
    "\n",
    "# write yml file\n",
    "with open('VCC2SM1-VCC2TF1.yml', 'w') as fp:\n",
    "    yaml.dump(yml, fp)\n",
    "!cat VCC2SM1-VCC2TF1.yml\n",
    "os.chdir(egs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0020.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ```run_sprocket.py```\n",
    "After initialization, the main process is excuted by ```run_sprocket.py```\n",
    "\n",
    "## Options for ```run_sprocket.py```\n",
    "- -1: Acoustic feature extraction\n",
    "- -2: Estimate speaker-dependent statistics\n",
    "- -3: Estimate alignment\n",
    "- -4: Train GMM\n",
    "- -5: Conversion\n",
    "- <source_speaker\\>: Source speaker label (e.g., VCC2SM1)\n",
    "- <target_speaker\\>: Target speaker label (e.g., VCC2TF1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step1: Feature extraction\n",
    "## Extract acoustic feature vector in each speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# python3 run_sprocket -1 <source_speaker> <target_speaker>\n",
    "!python3 run_sprocket.py -1 VCC2SM1 VCC2TF1\n",
    "!echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0021.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confirm feature vector\n",
    "Feature vectors are stored into single HDF5 format file in each utterance.\n",
    "\n",
    "### Directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!tree -L 4 data/pair/VCC2SM1-VCC2TF1/h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Look inside of h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!h5ls data/pair/VCC2SM1-VCC2TF1/h5/VCC2SM1/10001.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- codeap: Coded aperiodicity\n",
    "- f0: Fundamental frequency\n",
    "- mcep: Mel-cepstrum\n",
    "- npow: Power sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0022.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step2: Speaker-dependent statisitcs estimation\n",
    "\n",
    "Estimate speaker-dependent statistics such as F0 and GV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!python3 run_sprocket.py -2 VCC2SM1 VCC2TF1\n",
    "!echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0023.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0024.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step3: Time-warping function extraction\n",
    "Estimate alignment between source and target feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!python3 run_sprocket.py -3 VCC2SM1 VCC2TF1\n",
    "!echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0025.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confirm output time-warping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!tree -L 3 data/pair/VCC2SM1-VCC2TF1/twf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sprocket.util import HDF5\n",
    "\n",
    "# read twf from hdf5 file\n",
    "h5 = HDF5('data/pair/VCC2SM1-VCC2TF1/twf/it2_10001.h5', 'a')\n",
    "twf = h5.read('twf')\n",
    "h5.close()\n",
    "\n",
    "# plot twf\n",
    "twf_mat = np.zeros((np.max(twf[1]) + 1, np.max(twf[0]) + 1))\n",
    "twf_mat[twf[1], twf[0]] = 1\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.xlabel('Source voice')\n",
    "plt.ylabel('Targert voice')\n",
    "plt.imshow(twf_mat, origin='lower')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0026.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step4: GMM training\n",
    "Train GMM using source and target feature vector and time-warping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!python3 run_sprocket.py -4 VCC2SM1 VCC2TF1\n",
    "!echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0027.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0028.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step5: Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!python3 run_sprocket.py -5 VCC2SM1 VCC2TF1\n",
    "!echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0029.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0030.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0031.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "print(\"Source voice\")\n",
    "IPython.display.display(IPython.display.Audio(\"data/wav/VCC2SM1/30001.wav\"))\n",
    "print(\"Target voice\")\n",
    "IPython.display.display(IPython.display.Audio(\"data/wav/VCC2TF1/30001.wav\"))\n",
    "print(\"Converted by VC\")\n",
    "IPython.display.display(IPython.display.Audio(\"data/pair/VCC2SM1-VCC2TF1/test/VCC2SM1/30001_VC.wav\"))\n",
    "print(\"Converted by DIFFVC\")\n",
    "IPython.display.display(IPython.display.Audio(\"data/pair/VCC2SM1-VCC2TF1/test/VCC2SM1/30001_DIFFVC.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0032.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"sprocket_png/image0033.png\" width=85%>\n",
    "<div align=\"center\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "ITTutorial.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
